{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import math\n",
    "import random\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.engine import Layer\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate, Activation, Dense, Dropout, Flatten, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory error, so to feed model in batches\n",
    "batch_size = 20\n",
    "train_dir = '../Capstone/train_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom image augmentation function\n",
    "def custom_preprocessing(image):\n",
    "    state = random.randint(0,2)\n",
    "    if state == 0:\n",
    "        processed_img = exposure.equalize_adapthist((image*1.0/255), clip_limit=0.02)\n",
    "    elif state == 1:\n",
    "        processed_img = exposure.equalize_hist(image)\n",
    "    elif state == 2:\n",
    "        p2, p98 = np.percentile(image, (2,98))\n",
    "        processed_img = exposure.rescale_intensity(image, in_range=(p2,p98))\n",
    "    return processed_img\n",
    "\n",
    "image_gen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        preprocessing_function=custom_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAB range L (0,100); ab (-128,127)\n",
    "# a is green - red ; b is blue -yellow\n",
    "# function to split training set X train, y train and produce augmented images       \n",
    "def image_a_b_gen(batch_size):\n",
    "    for i in image_gen.flow_from_directory(train_dir, batch_size=batch_size, class_mode=None, shuffle=False):\n",
    "        lab_batch = (rgb2lab(i))\n",
    "        #normalize the ab channels to 0-1\n",
    "        lab_scaled = (lab_batch) / [100, 255, 255]\n",
    "        X_train = lab_scaled[:,:,:,0]\n",
    "        X_train = X_train.reshape(X_train.shape+(1,))\n",
    "        y_train = lab_scaled[:,:,:,1:]\n",
    "        yield ([X_train, y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSSIMObjective:\n",
    "    def __init__(self, k1=0.01, k2=0.03, max_value=1.0):\n",
    "        self.__name__ = 'DSSIMObjective'\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.max_value = max_value\n",
    "        self.backend = K.backend()\n",
    "\n",
    "    def __int_shape(self, x):\n",
    "        return K.int_shape(x) if self.backend == 'tensorflow' else K.shape(x)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        ch = K.shape(y_pred)[-1]\n",
    "\n",
    "        def _fspecial_gauss(size, sigma):\n",
    "            #Function to mimic the 'fspecial' gaussian MATLAB function.\n",
    "            coords = np.arange(0, size, dtype=K.floatx())\n",
    "            coords -= (size - 1 ) / 2.0\n",
    "            g = coords**2\n",
    "            g *= ( -0.5 / (sigma**2) )\n",
    "            g = np.reshape (g, (1,-1)) + np.reshape(g, (-1,1) )\n",
    "            g = K.constant ( np.reshape (g, (1,-1)) )\n",
    "            g = K.softmax(g)\n",
    "            g = K.reshape (g, (size, size, 1, 1)) \n",
    "            g = K.tile (g, (1,1,ch,1))\n",
    "            return g\n",
    "                  \n",
    "        kernel = _fspecial_gauss(11,1.5)\n",
    "\n",
    "        def reducer(x):\n",
    "            return K.depthwise_conv2d(x, kernel, strides=(1, 1), padding='valid')\n",
    "\n",
    "        c1 = (self.k1 * self.max_value) ** 2\n",
    "        c2 = (self.k2 * self.max_value) ** 2\n",
    "        \n",
    "        mean0 = reducer(y_true)\n",
    "        mean1 = reducer(y_pred)\n",
    "        num0 = mean0 * mean1 * 2.0\n",
    "        den0 = K.square(mean0) + K.square(mean1)\n",
    "        luminance = (num0 + c1) / (den0 + c1)\n",
    "        \n",
    "        num1 = reducer(y_true * y_pred) * 2.0\n",
    "        den1 = reducer(K.square(y_true) + K.square(y_pred))\n",
    "        c2 *= 1.0 #compensation factor\n",
    "        cs = (num1 - num0 + c2) / (den1 - den0 + c2)\n",
    "\n",
    "        ssim_val = K.mean(luminance * cs, axis=(-3, -2) )\n",
    "        return K.mean( (1.0 - ssim_val ) / 2.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_loss = DSSIMObjective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Downsampling batch\n",
    "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
    "model.add(Conv2D(64, (3, 3),activation='relu', padding='same'))                     \n",
    "model.add(BatchNormalization())                                               #(bs,256, 256,64)\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same', strides=2))            \n",
    "model.add(BatchNormalization())                                               #(bs,128,128,64)\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))                     \n",
    "model.add(BatchNormalization())                                                #(bs,128,128,128)\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',padding='same', strides=2))          \n",
    "model.add(BatchNormalization())                                                   #(bs,64,64,128)\n",
    "model.add(Conv2D(256, (3, 3), activation='relu',padding='same'))                     \n",
    "model.add(BatchNormalization())                                                 #(bs,64,64,256)\n",
    "model.add(Conv2D(256, (3, 3), activation='relu',padding='same', strides=2))            \n",
    "model.add(BatchNormalization())                                                    #(bs,32,32,256)\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',padding='same'))                     \n",
    "model.add(BatchNormalization())                                                   #(bs,32,32,512)\n",
    "\n",
    "#Upsampling batch\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))        \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))                                                       #(bs,32,32,512)\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))     \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))                                                       #(bs,32,32,256)\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))        \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))                                                       #(bs,32,32,128)\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))        \n",
    "model.add(BatchNormalization()) \n",
    "model.add(UpSampling2D((2, 2)))                                               #(bs,64,64,64)\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))        \n",
    "model.add(BatchNormalization())\n",
    "model.add(UpSampling2D((2, 2)))                                               #(bs,128,128,32)\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))         \n",
    "model.add(UpSampling2D((2, 2)))                                               #(bs,256,256,2)\n",
    "\n",
    "# Finish model\n",
    "model.compile(optimizer='rmsprop', loss=ssim_loss ,metrics=['mse','mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Found 9306 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\skimage\\exposure\\exposure.py:124: UserWarning: This might be a color image. The histogram will be computed on the flattened image. You can instead apply this function to each color channel.\n",
      "  warn(\"This might be a color image. The histogram will be \"\n",
      "C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:135: UserWarning: Possible precision loss when converting from float32 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:135: UserWarning: Possible precision loss when converting from float64 to float32\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/465 [..............................] - ETA: 4:18:15 - loss: 0.4999 - mean_squared_error: 0.4796 - mean_absolute_error: 0.6211"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit_generator(image_a_b_gen(batch_size), steps_per_epoch=(9306//batch_size), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/n3rDx/Desktop/Homework Upload/Capstone/5th_expt_rmsprop_lab_relu_NORM_10epochs.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load black and white images\n",
    "test = []\n",
    "for filename in os.listdir('../test_images/test'):\n",
    "        test.append(img_to_array(load_img('C:/Users/n3rDx/Desktop/Homework Upload/Capstone/test_images/test/'+filename)))\n",
    "test = np.array(test).astype('float')*1.0/255   #Original image must come in as (0,1)\n",
    "lab_test = (rgb2lab(test)[:,:,:,0])/100       #output after rgb2lab should be ([0:1,-1:1, -1:1])\n",
    "lab_test = lab_test.reshape(lab_test.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "output = model.predict(lab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    cur = np.zeros((256, 256, 3))\n",
    "    cur[:,:,0] = lab_test[i][:,:,0]\n",
    "    cur[:,:,1:] = output[i]\n",
    "    cur = (cur * [100, 255, 255])\n",
    "    picture = lab2rgb(cur)\n",
    "    picture *= 255\n",
    "    imsave(\"C:/Users/n3rDx/Desktop/Homework Upload/Capstone/results/\"+str(i)+\".jpg\", picture.astype('uint8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
