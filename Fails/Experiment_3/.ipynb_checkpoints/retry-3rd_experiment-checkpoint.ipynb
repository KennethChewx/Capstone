{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import math\n",
    "import random\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.engine import Layer\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate, Activation, Dense, Dropout, Flatten, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory error, so to feed model in batches\n",
    "# Image transformer\n",
    "batch_size = 20\n",
    "train_dir = '../Capstone/images/train/'\n",
    "\n",
    "def custom_preprocessing(image):\n",
    "    state = random.randint(0,2)\n",
    "    if state == 0:\n",
    "        processed_img = exposure.equalize_adapthist((image*1.0/255), clip_limit=0.02)\n",
    "    elif state == 1:\n",
    "        processed_img = exposure.equalize_hist(image)\n",
    "    elif state == 2:\n",
    "        p2, p98 = np.percentile(image, (2,98))\n",
    "        processed_img = exposure.rescale_intensity(image, in_range=(p2,p98))\n",
    "    return processed_img\n",
    "\n",
    "image_gen = ImageDataGenerator(\n",
    "        shear_range=0.4,\n",
    "        zoom_range=0.4,\n",
    "        vertical_flip=True,\n",
    "        preprocessing_function=custom_preprocessing)\n",
    "\n",
    "# function to split training set X train, y train and produce augmented images       \n",
    "def image_a_b_gen(batch_size):\n",
    "    for i in image_gen.flow_from_directory(train_dir, batch_size=batch_size,class_mode=None,shuffle=False):\n",
    "        lab_batch = rgb2lab(i)\n",
    "        X_train = lab_batch[:,:,:,0] / 100\n",
    "        X_train = X_train.reshape(X_train.shape+(1,))\n",
    "        y_train = lab_batch[:,:,:,1:] / 128\n",
    "        yield ([X_train, y_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSSIMObjective:\n",
    "    def __init__(self, k1=0.01, k2=0.03, max_value=1.0):\n",
    "        self.__name__ = 'DSSIMObjective'\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.max_value = max_value\n",
    "        self.backend = K.backend()\n",
    "\n",
    "    def __int_shape(self, x):\n",
    "        return K.int_shape(x) if self.backend == 'tensorflow' else K.shape(x)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        ch = K.shape(y_pred)[-1]\n",
    "\n",
    "        def _fspecial_gauss(size, sigma):\n",
    "            #Function to mimic the 'fspecial' gaussian MATLAB function.\n",
    "            coords = np.arange(0, size, dtype=K.floatx())\n",
    "            coords -= (size - 1 ) / 2.0\n",
    "            g = coords**2\n",
    "            g *= ( -0.5 / (sigma**2) )\n",
    "            g = np.reshape (g, (1,-1)) + np.reshape(g, (-1,1) )\n",
    "            g = K.constant ( np.reshape (g, (1,-1)) )\n",
    "            g = K.softmax(g)\n",
    "            g = K.reshape (g, (size, size, 1, 1)) \n",
    "            g = K.tile (g, (1,1,ch,1))\n",
    "            return g\n",
    "                  \n",
    "        kernel = _fspecial_gauss(11,1.5)\n",
    "\n",
    "        def reducer(x):\n",
    "            return K.depthwise_conv2d(x, kernel, strides=(1, 1), padding='valid')\n",
    "\n",
    "        c1 = (self.k1 * self.max_value) ** 2\n",
    "        c2 = (self.k2 * self.max_value) ** 2\n",
    "        \n",
    "        mean0 = reducer(y_true)\n",
    "        mean1 = reducer(y_pred)\n",
    "        num0 = mean0 * mean1 * 2.0\n",
    "        den0 = K.square(mean0) + K.square(mean1)\n",
    "        luminance = (num0 + c1) / (den0 + c1)\n",
    "        \n",
    "        num1 = reducer(y_true * y_pred) * 2.0\n",
    "        den1 = reducer(K.square(y_true) + K.square(y_pred))\n",
    "        c2 *= 1.0 #compensation factor\n",
    "        cs = (num1 - num0 + c2) / (den1 - den0 + c2)\n",
    "\n",
    "        ssim_val = K.mean(luminance * cs, axis=(-3, -2) )\n",
    "        return K.mean( (1.0 - ssim_val ) / 2.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_loss = DSSIMObjective()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shared models\n",
    "encoder_input = Input(shape=(256, 256, 1,))\n",
    "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = BatchNormalization()(encoder_output)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = BatchNormalization()(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output_shared = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "\n",
    "#Model A\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output_shared)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "#Model B\n",
    "global_encoder = Conv2D(512, (3,3), activation='relu', padding='same',strides=2)(encoder_output_shared)\n",
    "global_encoder = Conv2D(512, (3,3), activation='relu', padding='same')(global_encoder)\n",
    "global_encoder = BatchNormalization()(global_encoder)\n",
    "global_encoder = Conv2D(512, (3,3), activation='relu', padding='same',strides=2)(global_encoder)\n",
    "global_encoder = Conv2D(512, (3,3), activation='relu', padding='same')(global_encoder)\n",
    "global_encoder = BatchNormalization()(global_encoder)\n",
    "global_encoder = Flatten()(global_encoder)\n",
    "global_encoder = Dense(1024, activation='relu')(global_encoder)\n",
    "global_encoder = Dense(512, activation='relu')(global_encoder)\n",
    "global_encoder = Dense(256, activation='relu')(global_encoder)\n",
    "global_encoder = RepeatVector(32 * 32)(global_encoder)\n",
    "global_encoder = Reshape([32,32,256])(global_encoder)\n",
    "#Fusion \n",
    "fusion_output = concatenate([encoder_output, global_encoder], axis=3) \n",
    "fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output)\n",
    "#Decoder\n",
    "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "\n",
    "model = Model(inputs=encoder_input, outputs=decoder_output)\n",
    "# Finish model\n",
    "model.compile(optimizer='adam',loss=ssim_loss ,metrics=['mse','mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit_generator(image_a_b_gen(batch_size=batch_size), steps_per_epoch=10, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/n3rDx/Desktop/Homework Upload/Capstone/3rd_expt_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load black and white images\n",
    "test = []\n",
    "for filename in os.listdir('../Capstone/images/test/test/'):\n",
    "        test.append(img_to_array(load_img('C:/Users/n3rDx/Desktop/Homework Upload/Capstone/images/test/test/'+filename)))\n",
    "test = np.array(test, dtype=float)\n",
    "test = rgb2lab(test/255.0)[:,:,:,0]\n",
    "test = test.reshape(test.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "output = model.predict(test)\n",
    "output = output * 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "        cur = np.zeros((256, 256, 3))\n",
    "        cur[:,:,0] = color_me[i][:,:,0]\n",
    "        cur[:,:,1:] = output[i]\n",
    "        imsave(\"C:/Users/n3rDx/Desktop/Homework Upload/Capstone/result/\"+str(i)+\".jpg\", lab2rgb(cur).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
