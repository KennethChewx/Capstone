{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import keras\n",
    "import random\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.engine import Layer\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate, Activation, Dense, Dropout, Flatten, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import RepeatVector\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "from skimage.measure import compare_ssim as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "BUFFER_SIZE = 100\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(input_image, real_image, height, width):\n",
    "    input_image = tf.image.resize(input_image, [height, width],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = tf.image.resize(real_image, [height, width],\n",
    "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "def random_crop(input_image, real_image):\n",
    "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
    "    cropped_image = tf.image.random_crop(\n",
    "        stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image[0], cropped_image[1]\n",
    "# normalizing the images to [-1, 1]\n",
    "\n",
    "def normalize(input_image, real_image):\n",
    "    input_image = (input_image / 127.5) - 1\n",
    "    real_image = (real_image / 127.5) - 1\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "def random_jitter(input_image, real_image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    input_image, real_image = resize(input_image, real_image, 286, 286)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    input_image, real_image = random_crop(input_image, real_image)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        # random mirroring\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        real_image = tf.image.flip_left_right(real_image)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformer\n",
    "train_dir = 'C:/Users/n3rDx/Desktop/Homework Upload/Capstone/images/train/train'\n",
    "test_dir = 'C:/Users/n3rDx/Desktop/Homework Upload/Capstone/images/test/test'\n",
    "\n",
    "# function to split training set X train, y train and produce augmented images       \n",
    "def load(image_file):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    #Turn into tensor for generator and discriminator\n",
    "    X_train = tf.cast(image, tf.float32)\n",
    "    y_train = tf.cast(image, tf.float32)\n",
    "    #change to X_train to gray ; y_train as target color itself\n",
    "    X_train = tf.image.grayscale_to_rgb(tf.image.rgb_to_grayscale(X_train))\n",
    "    #normalize to scales of -1 and 1\n",
    "    X_train = (X_train/127.5) -1\n",
    "    y_train = (y_train/127.5) -1\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_train(image_file):\n",
    "    input_image, real_image = load(image_file)\n",
    "    #input_image, real_image = random_jitter(input_image, real_image)\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "def load_image_test(image_file):\n",
    "    input_image, real_image = load(image_file)\n",
    "    input_image, real_image = resize(input_image, real_image,\n",
    "                                   IMG_HEIGHT, IMG_WIDTH)\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.list_files(train_dir+'/*.jpg')\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.map(load_image_train,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(1)\n",
    "\n",
    "test_dataset = tf.data.Dataset.list_files(train_dir+'/*.jpg')\n",
    "# shuffling so that for every epoch a different image is generated\n",
    "# to predict and display the progress of our model.\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "test_dataset = test_dataset.map(load_image_test)\n",
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.list_files(train_dir + '/*.jpg')\n",
    "train_dataset = train_dataset.shuffle(200)\n",
    "train_dataset = train_dataset.map(load,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.list_files(train_dir+'/*.jpg')\n",
    "# shuffling so that for every epoch a different image is generated\n",
    "# to predict and display the progress of our model.\n",
    "train_dataset = train_dataset.shuffle(200)\n",
    "test_dataset = test_dataset.map(load)\n",
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom convu filter to downsample image\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "            tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom convu filter to upsample image\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "        downsample(128, 4), # (bs, 64, 64, 128)\n",
    "        downsample(256, 4), # (bs, 32, 32, 256)\n",
    "        downsample(512, 4), # (bs, 16, 16, 512)\n",
    "        downsample(512, 4), # (bs, 8, 8, 512)\n",
    "        downsample(512, 4), # (bs, 4, 4, 512)\n",
    "        downsample(512, 4), # (bs, 2, 2, 512)\n",
    "        downsample(512, 4), # (bs, 1, 1, 512)\n",
    "          ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "        upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "        upsample(256, 4), # (bs, 32, 32, 512)\n",
    "        upsample(128, 4), # (bs, 64, 64, 256)\n",
    "        upsample(64, 4), # (bs, 128, 128, 128)\n",
    "          ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(3, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=[None,None,3])\n",
    "    x = inputs\n",
    "\n",
    "  # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[None, None, 3], name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=[None, None, 3], name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "    down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
    "    down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "    down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lambda from article  \n",
    "lamb = 100\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    # mean absolute error\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "    total_gen_loss = gan_loss + (lamb * l1_loss)\n",
    "\n",
    "    return total_gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.train.AdamOptimizer(2e-4, beta1=0.5)\n",
    "discriminator_optimizer = tf.train.AdamOptimizer(2e-4, beta1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for input_image, target in dataset:\n",
    "            train_step(input_image, target)\n",
    "\n",
    "        for inp, tar in test_dataset.take(1):\n",
    "            generate_images(generator, inp, tar)\n",
    "            \n",
    "        print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                        time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar):\n",
    "    prediction = model(test_input, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input_image, target):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        gen_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0625 10:48:26.948016  8740 deprecation.py:323] From C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "E0625 10:49:52.465279  8740 ultratb.py:149] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-19-a2a5b69d0aca>\", line 1, in <module>\n",
      "    train(train_dataset, epochs=10)\n",
      "  File \"<ipython-input-15-96bb8947784e>\", line 6, in train\n",
      "    train_step(input_image, target)\n",
      "  File \"<ipython-input-17-17b356ae608d>\", line 12, in train_step\n",
      "    generator.trainable_variables)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\", line 980, in gradient\n",
      "    unconnected_gradients=unconnected_gradients)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\", line 76, in imperative_grad\n",
      "    compat.as_str(unconnected_gradients.value))\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\", line 137, in _gradient_function\n",
      "    return grad_fn(mock_op, *out_grads)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 142, in _MeanGrad\n",
      "    output_shape = array_ops.shape(op.outputs[0])\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 330, in shape\n",
      "    return shape_internal(input, name, optimize=True, out_type=out_type)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 357, in shape_internal\n",
      "    return constant(input_shape.as_list(), out_type, name=name)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 246, in constant\n",
      "    allow_broadcast=True)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 290, in _constant_impl\n",
      "    name=name).outputs[0]\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2021, in __init__\n",
      "    op_def = self._graph._get_op_def(node_def.op)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 4005, in _get_op_def\n",
      "    c_api.TF_GraphGetOpDef(self._c_graph, compat.as_bytes(type), buf)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\n3rDx\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "train(train_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar):\n",
    "  # the training=True is intentional here since\n",
    "  # we want the batch statistics while running the model\n",
    "  # on the test dataset. If we use training=False, we will get\n",
    "  # the accumulated statistics learned from the training dataset\n",
    "  # (which we don't want)\n",
    "    prediction = model(test_input, training=True)\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    display_list = [test_input[0], tar[0], prediction[0]]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the trained model on the entire test dataset\n",
    "for inp, tar in test_dataset.take(5):\n",
    "  generate_images(generator, inp, tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
