{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import random\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.engine import Layer\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate, Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import RepeatVector, Permute\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Second experiment testing on 200 images\n",
    "'''\n",
    "imgs = []\n",
    "for filename in os.listdir('few_images/train'):\n",
    "    imgs.append(img_to_array(load_img('C:/Users/n3rDx/Desktop/Homework Upload/Capstone/few_images/train/'+filename)))\n",
    "imgs = np.array(imgs, dtype=float)\n",
    "''' \n",
    "Convert RBG 255 colors into base 2 binary for computational ease (binary)\n",
    "RGB coefficients from 0-255 would be too high for our model to process (given a typical learning rate),\n",
    "thus convert to range 0-1.0\n",
    "'''\n",
    "imgs = 1.0/255*imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformer\n",
    "image_gen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "# function to split training set X train, y train and produce augmented images\n",
    "def image_a_b_gen(batch_size):\n",
    "    for i in image_gen.flow(imgs, batch_size=batch_size):\n",
    "        lab = rgb2lab(i)\n",
    "        X_train = lab[:,:,:,0]\n",
    "        y_train = lab[:,:,:,1:] / 128\n",
    "        yield (X_train.reshape(X_train.shape+(1,)), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "\n",
    "# Finish model\n",
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "TensorBoard(log_dir='/output')\n",
    "model.fit_generator(image_a_b_gen(batch_size), steps_per_epoch=4000, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5cbe0b043687>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/n3rDx/Desktop/Homework Upload/Capstone/2nd_expt_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load black and white images\n",
    "test = []\n",
    "for filename in os.listdir('few_images/test'):\n",
    "        test.append(img_to_array(load_img('C:/Users/n3rDx/Desktop/Homework Upload/Capstone/few_images/test/'+filename)))\n",
    "test = np.array(test, dtype=float)\n",
    "test = rgb2lab(test/255.0)[:,:,:,0]\n",
    "test = test.reshape(test.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "output = model.predict(test)\n",
    "output = output * 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0620 13:57:34.054287  7432 util.py:64] Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "W0620 13:57:34.098318  7432 util.py:64] Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "W0620 13:57:34.126340  7432 util.py:64] Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "W0620 13:57:34.170369  7432 util.py:64] Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "W0620 13:57:34.211398  7432 util.py:64] Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "W0620 13:57:34.254430  7432 util.py:64] Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "W0620 13:57:34.299462  7432 util.py:64] Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "        cur = np.zeros((256, 256, 3))\n",
    "        cur[:,:,0] = test[i][:,:,0]\n",
    "        cur[:,:,1:] = output[i]\n",
    "        imsave(\"C:/Users/n3rDx/Desktop/Homework Upload/Capstone/few_images/result/\"+str(i)+\".jpg\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train = imgs[:195]\n",
    "test = imgs[195:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import map images into the lightness - a/b colorspace\n",
    "X_test = rgb2lab(test)[:,:,:,0]\n",
    "y_test = rgb2lab(test)[:,:,:,1:]/128\n",
    "X_train = rgb2lab(train)[:,:,:,0]\n",
    "y_train = rgb2lab(train)[:,:,:,1:]/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape for input into CNN\n",
    "X_train = X_train.reshape(X_train.shape+(1,))\n",
    "X_test = X_test.reshape(X_test.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the neural network\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
